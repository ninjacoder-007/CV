{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Explain convolutional neural network, and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "When it comes to Machine Learning, Artificial Neural Networks perform really well. Artificial Neural Networks are used in various classification tasks like image, audio, words. Different types of Neural Networks are used for different purposes, for example for predicting the sequence of words we use Recurrent Neural Networks more precisely an LSTM, similarly for image classification we use Convolution Neural networks. In this blog, we are going to build a basic building block for CNN. Before diving into the Convolution Neural Network, let us first revisit some concepts of Neural Network. In a regular Neural Network there are three types of layers:\n",
    "\n",
    "Input Layers: It’s the layer in which we give input to our model. The number of neurons in this layer is equal to the total number of features in our data (number of pixels in the case of an image).\n",
    "\n",
    "Hidden Layer: The input from the Input layer is then feed into the hidden layer. There can be many hidden layers depending upon our model and data size. Each hidden layer can have different numbers of neurons which are generally greater than the number of features. The output from each layer is computed by matrix multiplication of output of the previous layer with learnable weights of that layer and then by the addition of learnable biases followed by activation function which makes the network nonlinear.\n",
    "\n",
    "Output Layer: The output from the hidden layer is then fed into a logistic function like sigmoid or softmax which converts the output of each class into the probability score of each class.\n",
    "\n",
    "The data is then fed into the model and output from each layer is obtained this step is called feedforward, we then calculate the error using an error function, some common error functions are cross-entropy, square loss error, etc. After that, we backpropagate into the model by calculating the derivatives. This step is called Backpropagation which basically is used to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. How does refactoring parts of your neural network definition favor you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c80e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep neural networks (DNN) are growing in capability and applicability. Their effectiveness has led to their use in safety critical and autonomous systems, yet there is a dearth of cost-effective methods available for reasoning about the behavior of a DNN. In this paper, we seek to expand the applicability and scalability of existing DNN verification techniques through DNN refactoring. A DNN refactoring defines (a) the transformation of the DNN's architecture, i.e., the number and size of its layers, and (b) the distillation of the learned relationships between the input features and function outputs of the original to train the transformed network. Unlike with traditional code refactoring, DNN refactoring does not guarantee functional equivalence of the two networks, but rather it aims to preserve the accuracy of the original network while producing a simpler network that is amenable to more efficient property verification. We present an automated framework for DNN refactoring, and demonstrate its potential effectiveness through three case studies on networks used in autonomous systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b98e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f14862",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.\n",
    "\n",
    "It needs to be in the MNIST CNN in the form of a 1-dimensional linear vector. Rectangular or cubic shapes can't be direct inputs. And this is why we need flattening and fully-connected layers. Flattening is converting the data into a 1-dimensional array for inputting it to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. What exactly does NCHW stand for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05162db",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCHW\" means a data whose layout is (batch_size, channel, height, width)\n",
    "\n",
    "N: batch size\n",
    "\n",
    "C: channel\n",
    "\n",
    "H: height\n",
    "\n",
    "W: width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explain definition of receptive field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3352df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Receptive field, region in the sensory periphery within which stimuli can influence the electrical activity of sensory cells. The receptive field encompasses the sensory receptors that feed into sensory neurons and thus includes specific receptors on a neuron as well as collectives of receptors that are capable of activating a neuron via synaptic connections. Receptive fields are found throughout the body, including over the body surface; in tissues such as muscles, joints, and the eyes; and in internal organs. The concept of the receptive field is central to sensory neurobiology, because it provides a description of the location at which a sensory stimulus must be presented in order to elicit a response from a sensory cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the scale of an activation's receptive field after two stride-2 convolutions? What is the reason for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a deep learning context, the Receptive Field (RF) is defined as the size of the region in the input that produces the feature. Basically, it is a measure of association of an output feature (of any layer) to the input region (patch).\n",
    "\n",
    "If all strides are 1, then the receptive field will simply be the sum of (kl−1) ( k l − 1 ) over all layers, plus 1, which is simple to see. If the stride is greater than 1 for a particular layer, the region increases proportionally for all layers below that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. What is the tensor representation of a color image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d57e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A colored image is actually a set of gray scale images each corresponding to a primary color channel. In the case of RGB we have three channels red, green, and blue and each of these channels contains the pixels of the image in that particular color. This can be represented by an order three tensor and there are two major ordering conventions. If we think of the image as a list of three single color images like the one in the figure, then the axis order will be channels first, then height, and then width. On the other hand, we can also think of this image tensor as an order two list of vector pixels where each pixel contains three numbers and each of these three numbers represents a color. This is called channel last and it's the convention we'll use in the rest of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. How does a color input interact with a convolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "The CNN only has the data to learn if color is a decisive factor for recognizing an object or not. If you only present it with red 'A's, it will learn that red is a decisive factor for recognizing the 'A'. By presenting it with a large number of different 'A's that are colored differently. The CNN will learn that color has little influence in recognizing an 'A'. The weight of the red channels or red features will not be dominant. You might even find that the CNN will learn grayscale filters instead of color sensitive filters.\n",
    "\n",
    "The color distribution for some objects, especially natural objects like those in ImageNet is not uniform. This results in the CNN learning color sensitive filters. After training the filters will be weighted according to the distribution with which it can recognize the object with least amount of error.\n",
    "\n",
    "For instances of objects that may be appear in different colors, where these colors are arbitrary (e.g. letters or digits on a sign/poster) we need to present sufficient examples for the CNN to untangle color information from recognizing those letters and digits. If it happens to only recognize red 'A's, it's because we never showed it otherwise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
