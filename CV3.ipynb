{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc09519",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. After each stride-2 conv, why do we double the number of filters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "“When we use a stride-2 convolution, we often increase the number of features because we’re decreasing the number of activations in the activation map by a factor of 4; we don’t want to decrease the capacity of a layer by too much at a time.”\n",
    "\n",
    "There is one bias for each channel. (Sometimes channels are called features or filters when they are not input channels.) The output shape is 64x4x14x14, and this will therefore become the input shape to the next layer. The next layer, according to summary, has 296 parameters. Let’s ignore the batch axis to keep things simple. So for each of 1414=196 locations we are multiplying 296-8=288 weights (ignoring the bias for simplicity), so that’s 196288=56_448 multiplications at this layer. The next layer will have 77(1168-16)=56_448 multiplications.\n",
    "\n",
    "What happened here is that our stride-2 convolution halved the grid size from 14x14 to 7x7, and we doubled the number of filters from 8 to 16, resulting in no overall change in the amount of computation. If we left the number of channels the same in each stride-2 layer, the amount of computation being done in the net would get less and less as it gets deeper. But we know that the deeper layers have to compute semantically rich features (such as eyes or fur), so we wouldn’t expect that doing less computation would make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Why do we use a larger kernel with MNIST (with simple cnn) in the first conv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f84dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "The basic principle followed in building a deep neural network is as follows:keep the feature space wide and shallow in the initial stages of the network, and the make it narrower and deeper towards the end.\n",
    "\n",
    "By width, I am referring to the 2D size (width/height), and the depth is same as the number of filters used to generate the features . The intuition behind keeping the feature space wide at the start by using smaller filters is to collect as much local information as possible, and then gradually increase the filter width to reduce the generated feature space width to represent more global, high-level and representative information. Also, the number of filters is increased to increase the depth of the feature space thus helping in learning more levels of global abstract structures. One more utility of making the feature space deeper and narrower is to make the feature space structurally or configuration-wise more compatible with the linear layers/classifiers that one usually uses in deep networks.\n",
    "\n",
    "For eg. it has been observed that the initial layers in a deep network for computer vision looks like Gabor filters basically hunts for edges, slants and blobs which are local low-level features. On the contrary, the deeper layers are actually represent high-level features like object parts or other discriminatory/representative details of the images which are not as local as the initial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What data is saved by ActivationStats for each layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab845cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivationStats saves the layer activations in self.stats for all modules passed to it. By default it will save activations for all modules. The saved stats is a FloatTensor of shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. How do we get a learner's callback after they've completed training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e507a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic class handling tweaks of the training loop by changing a Learner in various events\n",
    "\n",
    "The training loop is defined in Learner a bit below and consists in a minimal set of instructions: looping through the data we:\n",
    "\n",
    "compute the output of the model from the input\n",
    "calculate a loss between this output and the desired target\n",
    "compute the gradients of this loss with respect to all the model parameters\n",
    "update the parameters accordingly\n",
    "zero all the gradients\n",
    "Any tweak of this training loop is defined in a Callback to avoid over-complicating the code of the training loop, and to make it easy to mix and match different techniques (since they'll be defined in different callbacks). A callback can implement actions on the following events:\n",
    "\n",
    "Callbacks can occur at any of these times:: after_create before_fit before_epoch before_train before_batch after_pred after_loss before_backward before_step after_step after_cancel_batch after_batch after_cancel_train after_train before_validate after_cancel_validate after_validate after_cancel_epoch after_epoch after_cancel_fit after_fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What are the drawbacks of activations above zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "If the activations are above zero, learning the patter of data for the next layer not easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.Draw up the benefits and drawbacks of practicing in larger batches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad173e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "There is a tradeoff for bigger and smaller batch size which have their own disadvantage, making it a hyperparameter to tune in some sense. Theory says that, bigger the batch size, lesser is the noise in the gradients and so better is the gradient estimate. This allows the model to take a better step towards a minima.\n",
    "\n",
    "Our results concluded that a higher batch size does not usually achieve high accuracy, and the learning rate and the optimizer used will have a significant impact as well. Lowering the learning rate and decreasing the batch size will allow the network to train better, especially in the case of fine-tuning.\n",
    "\n",
    "Using too large a batch size can have a negative effect on the accuracy of your network during training since it reduces the stochasticity of the gradient descent.\n",
    "\n",
    "Those are called mini-batches. You lose the effectiveness of vectorization (Stacking the weights together and avoid For loops) if they are too small. It's going to produce a noisier (Higher cost in one iteration, lower cost in another iteration) gradient descent (Stochastic Gradient Descent).\n",
    "\n",
    "Moreover, by using bigger batch sizes (up to a reasonable amount that is allowed by the GPU), we speed up training, as it is equivalent to taking a few big steps, instead of taking many little steps. Therefore with bigger batch sizes, for the same amount of epochs, we can sometimes have a 2x gain in computational time!\n",
    "\n",
    "the distribution of gradients for larger batch sizes has a much heavier tail. better solutions can be far away from the initial weights and if the loss is averaged over the batch then large batch sizes simply do not allow the model to travel far enough to reach the better solutions for the same number of training\n",
    "\n",
    "Batch size controls the accuracy of the estimate of the error gradient when training neural networks. Batch, Stochastic, and Minibatch gradient descent are the three main flavors of the learning algorithm. There is a tension between batch size and the speed and stability of the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7aa488",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Why should we avoid starting training with a high learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "If your learning rate is set too low, training will progress very slowly as you are making very tiny updates to the weights in your network. However, if your learning rate is set too high, it can cause undesirable divergent behavior in your loss function.\n",
    "\n",
    "Large learning rates puts the model at risk of overshooting the minima so it will not be able to converge: what is known as exploding gradient.\n",
    "\n",
    "We should choose the learning rate very carefully since it should neither be very large that the optimal solution is missed and nor should be very low that it takes forever for the network to converge. When we define a neural network, we assign random weights and bias values to our nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af84d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. What are the pros of studying with a high rate of learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution, whereas a learning rate that is too small can cause the process to get stuck. The learning rate is perhaps the most important hyperparameter. If you have time to tune only one hyperparameter, tune the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Why do we want to end the training with a low learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05920f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generally, a large learning rate allows the model to learn faster, at the cost of arriving on a sub-optimal final set of weights. A smaller learning rate may allow the model to learn a more optimal or even globally optimal set of weights but may take significantly longer to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
